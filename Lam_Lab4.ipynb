{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\"> Lab Assignement 4: Statistical Learning and Predictive Analysis </span>\n",
    "- due Friday, November 10 @7PM\n",
    "- post to your Google Drive folder using the file name: LASTNAME_lab4.ipynb\n",
    "\n",
    "#### TYPE YOUR FULL NAME HERE: \n",
    "\n",
    "Riva Lam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grade (to be entered by TA):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <span style=\"color:darkblue\"> Question 1.\n",
    "\n",
    "(MDSR Exercise 8.1) The ability to get a good night’s sleep is correlated with many positive health outcomes. The NHANES data set contains a binary variable SleepTrouble that indicates whether each person has trouble sleeping. For this problem, you will need to install the NHANES package using the install.packages() function, and then call it using the library() function. The name of the dataframe is NHANES.\n",
    "\n",
    "Using each of the following approaches: **(a) Random Forests** and **(b) k-NN**: \n",
    "\n",
    "1. Build a classifier for SleepTrouble\n",
    "2. Report its effectiveness on the NHANES training data\n",
    "4. Interpret the results. What have you learned about people’s sleeping habits?\n",
    "\n",
    "\n",
    "\n",
    "*You may use whatever variable you like, except for SleepHrsNight.*\n",
    "\n",
    "#### SOLUTION:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: dplyr\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "Loading required package: lattice\n",
      "Loading required package: ggformula\n",
      "Loading required package: ggplot2\n",
      "Loading required package: ggstance\n",
      "\n",
      "Attaching package: ‘ggstance’\n",
      "\n",
      "The following objects are masked from ‘package:ggplot2’:\n",
      "\n",
      "    geom_errorbarh, GeomErrorbarh\n",
      "\n",
      "\n",
      "New to ggformula?  Try the tutorials: \n",
      "\tlearnr::run_tutorial(\"introduction\", package = \"ggformula\")\n",
      "\tlearnr::run_tutorial(\"refining\", package = \"ggformula\")\n",
      "Loading required package: mosaicData\n",
      "Loading required package: Matrix\n",
      "\n",
      "The 'mosaic' package masks several functions from core packages in order to add \n",
      "additional features.  The original behavior of these functions should not be affected by this.\n",
      "\n",
      "Note: If you use the Matrix package, be sure to load it BEFORE loading mosaic.\n",
      "\n",
      "Attaching package: ‘mosaic’\n",
      "\n",
      "The following object is masked from ‘package:Matrix’:\n",
      "\n",
      "    mean\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    stat\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    count, do, tally\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n",
      "    quantile, sd, t.test, var\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    max, mean, min, prod, range, sample, sum\n",
      "\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in library(mdsr): there is no package called ‘mdsr’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(mdsr): there is no package called ‘mdsr’\nTraceback:\n",
      "1. library(mdsr)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "# Random Forest - collection of decision trees that are aggregated by majority rule. A collection \n",
    "# bootstrapped decision trees. \n",
    "#A) random forest \n",
    "library(mosaic)\n",
    "library(mdsr)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "install.packages(\"NHANES\", repos='http://cran.us.r-project.org')\n",
    "library(NHANES)\n",
    "dim(NHANES)\n",
    "FILTER_SleepHrsNight<-filter(NHANES,!is.na(SleepHrsNight))\n",
    "dim(FILTER_SleepHrsNight)\n",
    "FILTER_DAYSPHYSHLTHBAD<-filter(FILTER_SleepHrsNight, !is.na(DaysPhysHlthBad))\n",
    "dim(FILTER_DAYSPHYSHLTHBAD)\n",
    "FILTER_DEPRESSED<-filter(FILTER_DAYSPHYSHLTHBAD,!is.na(Depressed))\n",
    "dim(FILTER_DEPRESSED)\n",
    "NHANES<-filter(FILTER_DEPRESSED,!is.na(HHIncome))\n",
    "install.packages(\"randomForest\", repos='http://cran.us.r-project.org')\n",
    "library(randomForest)\n",
    "set.seed(364) \n",
    "n <- nrow(NHANES) \n",
    "head(NHANES)\n",
    "test_idx <- sample.int(n, size = round(0.2 * n)) \n",
    "train <- NHANES[-test_idx, ] \n",
    "nrow(train)\n",
    "test <- NHANES[test_idx, ]\n",
    "nrow(test) \n",
    "tally(~SleepTrouble, data = train, format = \"percent\")\n",
    "library(rpart)  \n",
    "rpart(SleepTrouble ~ ., data = train)\n",
    "\n",
    "form <- as.formula(\"SleepTrouble ~ SleepHrsNight + DaysPhysHlthBad + Depressed + HHIncome\")\n",
    "mod_forest<-randomForest(form,data=train,ntree=201,mtry=4)\n",
    "#Is mtry= 4 selecting the exact 4 variables as seen in form? \n",
    "#You have to make sure all of the columns are filtered of NAs before doing random forests?\n",
    "#How do I read a confusion matrix? \n",
    "#How do I interpret the results. What have you learned about people’s sleeping habits?\n",
    "\n",
    "mod_forest\n",
    "sum(diag(mod_forest$confusion))/nrow(train)\n",
    "\n",
    "#sleep trouble= NHANES\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1.\n",
    "library(tibble)\n",
    "importance(mod_forest)%>% as.data.frame()%>%rownames_to_column()%>%arrange(desc(MeanDecreaseGini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2. \n",
    "library(class)\n",
    "library(dplyr)\n",
    "nums <- sapply(NHANES,is.numeric)#all the columns are that are numeric\n",
    "newNHANES <- NHANES[,nums] #columns that are numbers \n",
    "newNHANES2 <- data.frame(newNHANES,SleepTrouble = NHANES$SleepTrouble) #include SleepTrouble in \n",
    "firstfilter <- filter(newNHANES2, !is.na(DaysPhysHlthBad), !is.na(HHIncomeMid),!is.na(SleepHrsNight), !is.na(Age),!is.na(Poverty),\n",
    "                     !is.na(Weight), !is.na(Height), !is.na(SmokeAge), !is.na(AlcoholDay), !is.na(SexNumPartnLife), !is.na(SexAge), !is.na(SexNumPartYear),\n",
    "                     !is.na(SleepTrouble)) \n",
    "\n",
    "#Get rid of all NAS in columns\n",
    "filteredforknn <- select(firstfilter,'DaysPhysHlthBad', 'Age','HHIncomeMid', 'SleepHrsNight','SleepTrouble',\n",
    "                        'Weight', 'Height','SmokeAge', 'AlcoholDay', 'SexNumPartnLife','SexAge', 'SexNumPartYear')\n",
    "#Select columns without NAS\n",
    "\n",
    "n <- nrow(filteredforknn) \n",
    "head(NHANES)\n",
    "test_idx <- sample.int(n, size = round(0.2 * n)) \n",
    "train <- filteredforknn[-test_idx, ] \n",
    "nrow(train)\n",
    "test <- filteredforknn[test_idx, ]\n",
    "nrow(test) \n",
    "train_q <- train %>%\n",
    "select(DaysPhysHlthBad, Age, HHIncomeMid, SexAge, SmokeAge, Weight, Height, AlcoholDay, SleepHrsNight)\n",
    "sleeptrouble_knn <- knn(train_q, test = train_q, cl=train$SleepTrouble, k =10)\n",
    "confusionknn1 <- tally(sleeptrouble_knn ~SleepTrouble, data = train, format = \"count\")\n",
    "confusionknn1\n",
    "\n",
    "sum(diag(confusionknn1))/nrow(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution in words goes here\n",
    "\n",
    "Random Forest\n",
    "\n",
    "HHIncome is the highest predictor, followed by DaysPhysHlthBad, SleepHrsNight, and Depressed.This decision tree classifier is now 76.68% a considerable improvement over the null model. The model has an error rate of 23.21% of the time.The case where the outcome is Yes but the predicted data is No shows up 331 times, while the case where the outcome is No but the predicted data is Yes shows up 811 times\n",
    "\n",
    "\n",
    "\n",
    "KNN CLASSIFIER.\n",
    "\n",
    "For the KNN Classifier, this classifier is now 72.73% a considerable improvement over the null model. The model has an error rate of 7.27%.The case where the outcome is Yes but the predicted data is No shows up 251  times, while the case where the outcome is No but the predicted data is Yes shows up 71 times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <span style=\"color:darkblue\"> Question 2.\n",
    "\n",
    "(MDSR Exercise 8.3)  Repeat Question 1 but this time first separate the NHANES data set at random into 75% training and 25% testing sets (test sample).  Compare the effectiveness of each model on training vs. testing data.\n",
    "\n",
    "#### SOLUTION:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2. Training data with 25% test sample \n",
    "library(mosaic)\n",
    "library(mdsr)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "install.packages(\"NHANES\", repos='http://cran.us.r-project.org')\n",
    "library(NHANES)\n",
    "dim(NHANES)\n",
    "FILTER_SleepHrsNight<-filter(NHANES,!is.na(SleepHrsNight))\n",
    "dim(FILTER_SleepHrsNight)\n",
    "FILTER_DAYSPHYSHLTHBAD<-filter(FILTER_SleepHrsNight, !is.na(DaysPhysHlthBad))\n",
    "dim(FILTER_DAYSPHYSHLTHBAD)\n",
    "FILTER_DEPRESSED<-filter(FILTER_DAYSPHYSHLTHBAD,!is.na(Depressed))\n",
    "dim(FILTER_DEPRESSED)\n",
    "NHANES<-filter(FILTER_DEPRESSED,!is.na(HHIncome))\n",
    "install.packages(\"randomForest\", repos='http://cran.us.r-project.org')\n",
    "library(randomForest)\n",
    "set.seed(364) \n",
    "n <- nrow(NHANES) \n",
    "head(NHANES)\n",
    "test_idx <- sample.int(n, size = round(0.25 * n)) ----\n",
    "train <- NHANES[-test_idx, ] ----\n",
    "nrow(train)\n",
    "test <- NHANES[test_idx, ]\n",
    "nrow(test) \n",
    "tally(~SleepTrouble, data = train, format = \"percent\")\n",
    "library(rpart)  \n",
    "rpart(SleepTrouble ~ ., data = train)\n",
    "\n",
    "form <- as.formula(\"SleepTrouble ~ SleepHrsNight + DaysPhysHlthBad + Depressed + HHIncome\")\n",
    "mod_forest<-randomForest(form,data=train,ntree=201,mtry=4)#how many variables will be used from eahc tree. start with 10 variables and start ntry=4 each time fits tree \n",
    "mod_forest\n",
    "sum(diag(mod_forest$confusion))/nrow(train)\n",
    "library(tibble)\n",
    "importance(mod_forest)%>% as.data.frame()%>%rownames_to_column()%>%arrange(desc(MeanDecreaseGini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#KNN\n",
    "library(class)\n",
    "library(dplyr)\n",
    "nums <- sapply(NHANES,is.numeric)#all the columns are that are numeric\n",
    "newNHANES <- NHANES[,nums] #columns that are numbers \n",
    "newNHANES2 <- data.frame(newNHANES,SleepTrouble = NHANES$SleepTrouble) #include SleepTrouble in \n",
    "firstfilter <- filter(newNHANES2, !is.na(DaysPhysHlthBad), !is.na(HHIncomeMid),!is.na(SleepHrsNight), !is.na(Age),!is.na(Poverty),\n",
    "                     !is.na(Weight), !is.na(Height), !is.na(SmokeAge), !is.na(AlcoholDay), !is.na(SexNumPartnLife), !is.na(SexAge), !is.na(SexNumPartYear),\n",
    "                     !is.na(SleepTrouble)) \n",
    "\n",
    "#Get rid of all NAS in columns\n",
    "\n",
    "filteredforknn <- select(firstfilter,'DaysPhysHlthBad', 'Age','HHIncomeMid', 'SleepHrsNight','SleepTrouble',\n",
    "                        'Weight', 'Height','SmokeAge', 'SexNumPartnLife')\n",
    "#Select columns without NAS\n",
    "\n",
    "n <- nrow(filteredforknn) \n",
    "#head(NHANES)\n",
    "test_idx <- sample.int(n, size = round(0.25 * n)) \n",
    "train <- filteredforknn[-test_idx, ] \n",
    "#nrow(train)\n",
    "test <- filteredforknn[test_idx, ]\n",
    "#nrow(test) \n",
    "\n",
    "train_q <- train %>%\n",
    "select(DaysPhysHlthBad, Age, HHIncomeMid, SmokeAge, Weight, Height, SleepHrsNight)\n",
    "sleeptrouble_knn <- knn(train_q, test = train_q, cl=train$SleepTrouble, k =10)\n",
    "confusionknn1 <- tally(sleeptrouble_knn ~SleepTrouble, data = train, format = \"count\")\n",
    "\n",
    "sum(diag(confusionknn1))/nrow(train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For test\n",
    "test_idx <- sample.int(n, size = round(0.25 * n)) \n",
    "test <- filteredforknn[test_idx, ]\n",
    "names(test)\n",
    "testingdata<- test%>%\n",
    "select(DaysPhysHlthBad, Age, HHIncomeMid, SmokeAge, Weight, Height, SleepHrsNight)\n",
    "test_knn <- knn(testingdata, test = testingdata, cl=train$SleepTrouble, k =10)\n",
    "confusionknn2 <- tally(test_knn ~SleepTrouble, data = testingdata, format = \"count\")\n",
    "\n",
    "sum(diag(confusionknn2))/nrow(test_idx)\n",
    "#This is what I want to get and a number "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution in words goes here\n",
    "\n",
    "Repeat Question 1 but this time first separate the NHANES data set at random into 75% training and 25% testing sets (test sample).  Compare the effectiveness of each model on training vs. testing data.\n",
    "\n",
    "I would compare the effectiveness of each model on the training vs. testing data by running the confusion knn and knn classifier for the test. Then whatever value I obtained for the confusion matrix and the error rate for the test  I would compare it to the training. \n",
    "For the training model, the model is 76.93% improvement over the null model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
